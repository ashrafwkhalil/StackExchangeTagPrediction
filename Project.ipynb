{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import sys\n",
    "# Spark imports\n",
    "from pyspark.rdd import RDD\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql.functions import desc\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import split, col, udf, array_contains\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "from pyspark.sql.types import ArrayType, StringType, FloatType, IntegerType\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "from csv import reader\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_spark():\n",
    "    spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"Python Spark SQL basic example\") \\\n",
    "        .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "        .getOrCreate()\n",
    "    return spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<Font size=5 color=red>Investigate the original dataset (obviously, it cannot be used). Take a look at https://stackoverflow.com/questions/13793529/r-error-invalid-type-list-for-variable to see how useless the Body column information could be!\n",
    "\n",
    "The point here is that the body information consists mostly of codes and some weird patterns that are not useful for our purpose. The most important information here is the connection between the title of the questions and tags. So, I removed the Body column from the dataset.</Font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    spark = init_spark()\n",
    "\n",
    "    filename1 = \"./Train.csv\"\n",
    "    df2 = spark.read.option(\"multiLine\", 'true').option(\"escape\",\"\\'\").csv(filename1, header=True)\n",
    "    print(df2.count())\n",
    "    print(df2.show(10))    \n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<Font size=5 color=red>For removing the Body column, I read all the dataset once using Pandas library. After that, I removed the column and got an export to have a concrete file as our dataset. This part has been ommited from the notebook.</Font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = init_spark()\n",
    "\n",
    "filename = \"./TrainWithoutBody.csv\"\n",
    "df1 = spark.read.option(\"multiLine\", 'true').option(\"escape\",\"\\'\").csv(filename, header=True)\n",
    "df1 = df1.drop(\"_c0\")\n",
    "df1 = df1.dropna()\n",
    "\n",
    "rddTags = df1.select(\"Tags\").rdd\n",
    "\n",
    "# df1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<Font size = 5, color=green>Finding the 100 most used tags (one DT per each most used tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "splittedTags = rddTags.filter(lambda r: r[0] != None).flatMap(lambda r: r[0].split(\" \")).map(lambda r: (r, 1)).reduceByKey(lambda x, y: x + y)\n",
    "\n",
    "splittedTags = splittedTags.sortBy(lambda r: r[1], False) #Sorted with number of usage (you can collect and see)\n",
    "\n",
    "splittedTagsSorted = splittedTags.map(lambda r: r[0]) #Delete this line if you want to see number of times they have been used.\n",
    "\n",
    "# df10 = anSorted.toDF()\n",
    "\n",
    "\n",
    "mostUsedTags = splittedTagsSorted.collect()[0:50]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c#',\n",
       " 'java',\n",
       " 'php',\n",
       " 'javascript',\n",
       " 'android',\n",
       " 'jquery',\n",
       " 'c++',\n",
       " 'python',\n",
       " 'iphone',\n",
       " 'asp.net',\n",
       " 'mysql',\n",
       " 'html',\n",
       " '.net',\n",
       " 'ios',\n",
       " 'objective-c',\n",
       " 'sql',\n",
       " 'css',\n",
       " 'linux',\n",
       " 'ruby-on-rails',\n",
       " 'windows',\n",
       " 'c',\n",
       " 'sql-server',\n",
       " 'ruby',\n",
       " 'wpf',\n",
       " 'xml',\n",
       " 'ajax',\n",
       " 'database',\n",
       " 'regex',\n",
       " 'windows-7',\n",
       " 'asp.net-mvc',\n",
       " 'xcode',\n",
       " 'django',\n",
       " 'osx',\n",
       " 'arrays',\n",
       " 'vb.net',\n",
       " 'eclipse',\n",
       " 'json',\n",
       " 'facebook',\n",
       " 'ruby-on-rails-3',\n",
       " 'ubuntu',\n",
       " 'performance',\n",
       " 'networking',\n",
       " 'string',\n",
       " 'multithreading',\n",
       " 'winforms',\n",
       " 'security',\n",
       " 'asp.net-mvc-3',\n",
       " 'visual-studio-2010',\n",
       " 'bash',\n",
       " 'homework']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mostUsedTags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(rddTags.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rddTags.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<Font size=5.5, color=\"purpule\">Here, I have cleaned the Tags column to only contain the most used tags. For example, I ommited the \"upload\" tag from first group of tags for the first question, because it's not a most used tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replaceNoneWithString(x):\n",
    "    if (x == None): return \"None\"\n",
    "    else : return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subject titles to TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(inputCol=\"Title\", outputCol=\"transformed_tfidf\")\n",
    "wordsData = tokenizer.transform(df1)\n",
    "\n",
    "hashingTF = HashingTF(inputCol=\"transformed_tfidf\", outputCol=\"rawFeatures\", numFeatures=100)\n",
    "featurizedData = hashingTF.transform(wordsData)\n",
    "\n",
    "featurizedData.take(1)\n",
    "\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "idfModel = idf.fit(featurizedData)\n",
    "rescaledData = idfModel.transform(featurizedData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rescaledData.select(\"id\", \"title\", \"features\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up tags to include only most-used tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanUpTags(tags):\n",
    "    tags = tags.split(\" \")\n",
    "    tags = [tag for tag in tags if tag in mostUsedTags]\n",
    "    return tags\n",
    "\n",
    "cleanUpTagsUDF = udf(cleanUpTags, ArrayType(StringType()))\n",
    "\n",
    "\n",
    "df = rescaledData.withColumn(\"cleantags\",  cleanUpTagsUDF(col(\"tags\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3365"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def filterEmptyRows(tags):\n",
    "    return len(tags)\n",
    "\n",
    "filterEmptyRowsUDF = udf(filterEmptyRows, IntegerType())\n",
    "\n",
    "df = df.filter(filterEmptyRowsUDF(col(\"cleantags\")) > 0)\n",
    "# df.select(\"id\", \"title\", \"features\", \"cleantags\").show()\n",
    "df = df.sample(0.00083, 42)\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tag in mostUsedTags:\n",
    "    df = df.withColumn(tag, (array_contains(df.cleantags, tag)).cast('integer'))\n",
    "\n",
    "# df.select(\"Javascript\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data to test, train and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, testVal_data = df.randomSplit([.7,.3],seed=1234)\n",
    "test_data, validation_data = testVal_data.randomSplit([.5, .5], seed=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test_data.select(\"features\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train DecisionTreeClassifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtcs = defaultdict()\n",
    "preds = defaultdict()\n",
    "for tag in mostUsedTags:\n",
    "    dtcs[tag] = DecisionTreeClassifier(featuresCol=\"features\", labelCol=tag, maxDepth=2).fit(train_data)\n",
    "    preds[tag] = dtcs[tag].transform(validation_data)\n",
    "\n",
    "# dtc = DecisionTreeClassifier(featuresCol=\"features\", labelCol=\"javascript\", maxDepth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dtc = dtc.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred = dtc.transform(validation_data)\n",
    "# pred.select(\"javascript\", \"prediction\").show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluator=MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"javascript\")\n",
    "# acc = evaluator.evaluate(pred)\n",
    " \n",
    "# print(\"Prediction Accuracy: \", acc)\n",
    " \n",
    "# y_pred=pred.select(\"prediction\").collect()\n",
    "# y_orig=pred.select(\"javascript\").collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subject titles to Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use df as your dataframe and add your column to it "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
